{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9812ab-aeb9-43c8-bcc7-abf97428425c",
   "metadata": {
    "id": "2e9812ab-aeb9-43c8-bcc7-abf97428425c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8hd77s_FlJZd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "8hd77s_FlJZd",
    "outputId": "0bd343ca-043a-4681-a23d-7d1dbd644d30"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"https://www.sharkattackfile.net/spreadsheets/GSAF5.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e728df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914248a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run Shark_Quest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef1f8a-d455-449e-976d-a60d0d1038cc",
   "metadata": {
    "id": "7eef1f8a-d455-449e-976d-a60d0d1038cc"
   },
   "outputs": [],
   "source": [
    "to_use.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lt3nSI4ylQhB",
   "metadata": {
    "id": "Lt3nSI4ylQhB"
   },
   "outputs": [],
   "source": [
    "data_1 = df.copy() #making first copy just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7db21-60b6-4b93-8495-4a040daa5159",
   "metadata": {
    "id": "d7d7db21-60b6-4b93-8495-4a040daa5159"
   },
   "source": [
    "# making a new data set with columns that we want to work with instead of dropping columns\n",
    "\n",
    "Here's how and logic: To select multiple columns, use a list of column names within the selection brackets\n",
    "    The inner square brackets define a Python list with column names,\n",
    "    whereas the outer brackets are used to select the data from a pandas DataFrame.\n",
    "    The returned data type is a pandas DataFrame. This method does not affect the rows. so we retain original rows\n",
    "\n",
    "# justification for keeping columns\n",
    "\n",
    "    1)data: there might be a particular season for attacks -we want to avoid that\n",
    "    2)year: we may look at this long term or select a period of time later - say 10 years\n",
    "    3)type: as discussed - unprovoked attacks might signal how dangerous the shark type is\n",
    "    4)country and location: we want to circle the hotspots\n",
    "    5)injury: not sure but maybe fatal ones could be useful\n",
    "    6)species: to find which ones require conservation\n",
    "    # age and sex and all that - not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZV3MQ6LdlU1F",
   "metadata": {
    "id": "ZV3MQ6LdlU1F"
   },
   "outputs": [],
   "source": [
    "to_use = data_1[[\"Year\",\"Type\",\"Country\",\"Location\",\"Injury\",\"Species \"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3PKKfHJilX99",
   "metadata": {
    "id": "3PKKfHJilX99"
   },
   "outputs": [],
   "source": [
    "#next step is data cleaning and standardisation - column names require cleaning - \"species \"has a white space\n",
    "to_use.columns = to_use.columns.str.replace(' ', '')\n",
    "to_use.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2998b5-67ec-4869-a926-239d3a04573e",
   "metadata": {
    "id": "1c2998b5-67ec-4869-a926-239d3a04573e"
   },
   "outputs": [],
   "source": [
    "to_use.columns = to_use.columns.str.lstrip().str.rstrip()\n",
    "to_use.columns = to_use.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96276bf4-9282-4c5e-aee4-670cdee9985e",
   "metadata": {
    "id": "96276bf4-9282-4c5e-aee4-670cdee9985e"
   },
   "outputs": [],
   "source": [
    "to_use.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b3efd-d758-4ef9-912d-cbc5b2e5e487",
   "metadata": {
    "id": "ee0b3efd-d758-4ef9-912d-cbc5b2e5e487"
   },
   "outputs": [],
   "source": [
    "to_use.dtypes #have to clear nans or have a strategy to clear nans before casting types i suppose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QFCA3DO5mju-",
   "metadata": {
    "id": "QFCA3DO5mju-"
   },
   "outputs": [],
   "source": [
    "to_use.duplicated().sum() #check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WA4SFGibnxUH",
   "metadata": {
    "id": "WA4SFGibnxUH"
   },
   "outputs": [],
   "source": [
    "#drop the duplicates\n",
    "to_use = to_use.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7gA2FRnaN2",
   "metadata": {
    "id": "cb7gA2FRnaN2"
   },
   "outputs": [],
   "source": [
    "#checking for empty spaces\n",
    "to_use.eq(\" \").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b5fa4-866d-4228-8f31-94cf21e3bab8",
   "metadata": {
    "id": "ea8b5fa4-866d-4228-8f31-94cf21e3bab8"
   },
   "source": [
    "# tasks to do:\n",
    "    - cleaning data set based on nans and what remains\n",
    "    - duplicates\n",
    "    - standardisation of column values\n",
    "    - then value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ddc5f",
   "metadata": {},
   "source": [
    "# cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QjZxuIj108gB",
   "metadata": {
    "id": "QjZxuIj108gB"
   },
   "outputs": [],
   "source": [
    "# year column\n",
    "\n",
    "to_use['year'] = to_use['year'].astype(str).str.replace(\".0\", \"\")\n",
    "to_use['year'] = to_use['year'].replace('nan', '0')\n",
    "to_use['year'] = to_use['year'].astype(int)\n",
    "to_use = to_use[to_use[\"year\"] >= 2000] #we sorted the years starting in 2000 till the actual year because that is what we want to analyze\n",
    "to_use = to_use.sort_values(by=\"year\", ascending=True)\n",
    "to_use = to_use[to_use[\"year\"] < 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Cx07HOj4kqd",
   "metadata": {
    "id": "5Cx07HOj4kqd"
   },
   "outputs": [],
   "source": [
    "#column type\n",
    "unwanted= [\"Invalid\", \"Watercraft\", \"Questionable\", \"Sea Disaster\", \"Under investigation\", \"Unverified\",\"Unconfirmed\", \"Boat\", \"?\"]\n",
    "to_use= to_use[to_use[\"type\"].apply(lambda x: x not in unwanted)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hlfc2bKA5ksE",
   "metadata": {
    "id": "hlfc2bKA5ksE"
   },
   "outputs": [],
   "source": [
    "to_use[\"type\"] = to_use[\"type\"].replace(\" Provoked\", \"Provoked\")\n",
    "to_use[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fh2H47UsI8PI",
   "metadata": {
    "id": "Fh2H47UsI8PI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_use = to_use.dropna(subset=[\"type\"])\n",
    "to_use.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "doZ68Mitg-Vy",
   "metadata": {
    "id": "doZ68Mitg-Vy"
   },
   "outputs": [],
   "source": [
    "#checking for duplicates\n",
    "to_use.duplicated().sum()\n",
    "to_use.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKsfyobxffHL",
   "metadata": {
    "id": "PKsfyobxffHL"
   },
   "outputs": [],
   "source": [
    "#finding nan values in year, location, country\n",
    "to_use[\"location\"].isna().sum()\n",
    "to_use[\"country\"].isna().sum()\n",
    "to_use[\"year\"].isna().sum()   #i checked and there were none in year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yc9o9v_v0Hy5",
   "metadata": {
    "id": "yc9o9v_v0Hy5"
   },
   "outputs": [],
   "source": [
    "#dropping nan values in country and location\n",
    "to_use.dropna(subset = ['country', 'location'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0d24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories of injury\n",
    "\n",
    "injuries_1 = [\"no injury\", \"rammed\", \"knocked\"]\n",
    "injuries_2 = [\"lacer\"]\n",
    "injuries_3 = [\"minor\", \"bitten\", \"injured\", \"puncture\", \"superficial\", \"cut\", \"pinched\", \"bruised\", \"gash\",\n",
    "             \"mark\", \"struck\", \"torn\"]\n",
    "injuries_4 = [\"major\", \"sever\", \"significant\", \"broken\", \"injuries\", \"injury\", \"multiple\", \"serious\",\n",
    "              \"gashed\", \"avulsed\", \"large\", \"lost\", \"amputated\"]\n",
    "injuries_5 = [\"fatal\", \"death\"]\n",
    "boat = [\"boat\", \"hull\", \"dinghy\", \"kayak\"]\n",
    "scavenging = [\"scavenging\"]\n",
    "\n",
    "all_injuries = injuries_1 + injuries_2 + injuries_3 + injuries_4 + injuries_5 + boat + scavenging\n",
    "\n",
    "def injury_rating(j):\n",
    "\n",
    "    \"\"\"categorising entries in the injury column\"\"\"\n",
    "\n",
    "    j = j.lower()\n",
    "    for i in injuries_1:\n",
    "        if i in j:\n",
    "            return \"no injury\"\n",
    "    for i in injuries_2:\n",
    "        if i in j:\n",
    "            return \"lacerations\"\n",
    "    for i in injuries_3:\n",
    "        if i in j:\n",
    "            return \"minor injuries\"\n",
    "    for i in injuries_4:\n",
    "        if i in j:\n",
    "            return \"major injuries\"\n",
    "    for i in injuries_5:\n",
    "        if i in j:\n",
    "            return \"fatal\"\n",
    "    for i in scavenging:\n",
    "        if i in j:\n",
    "            return \"probably scavenging\"\n",
    "    for i in boat:\n",
    "        if i in j:\n",
    "            return \"material damage\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af917dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_use[\"injury\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorising injuries\n",
    "to_use.dropna(subset=\"injury\", inplace=True)\n",
    "to_use[\"injury\"] = to_use[\"injury\"].apply(injury_rating)\n",
    "to_use.dropna(subset=\"injury\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569dd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorising shark species\n",
    "\n",
    "sharks = [\"white shark\", \"tiger shark\", \"bull shark\", \"shortfin mako shark\",\n",
    "         \"lemon shark\", \"oceanic whitetip shark\", \"blue shark\", \"galapagos shark\", \"caribbean reef shark\",\n",
    "         \"dusky shark\", \"blacktip shark\", \"silky shark\", \"gray reef shark\", \"great hammerhead shark\",\n",
    "         \"blacktip reef shark\", \"sevengill shark\", \"sixgill shark\", \"nurse shark\",\n",
    "         \"sand tiger\", \"spotted wobbegong\", \"basking shark\", \"spinner shark\", \"bronze whaler\", \"blue pointer\"]\n",
    "\n",
    "def shark_species(value, sharks):\n",
    "    for shark in sharks:\n",
    "        if shark in value.lower():\n",
    "            return shark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68d0908",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_use.dropna(subset=\"species\", inplace=True)\n",
    "to_use[\"species\"] = to_use[\"species\"].apply(shark_species, args=(sharks,))\n",
    "to_use[\"species\"] = to_use[\"species\"].replace(\"blue pointer\", \"shortfin mako shark\")\n",
    "to_use.dropna(subset=\"species\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ecf68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4a4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OJEnZjao0H2B",
   "metadata": {
    "id": "OJEnZjao0H2B"
   },
   "outputs": [],
   "source": [
    "#top ten locations - not sure if we need this\n",
    "n=10\n",
    "to_use[\"location\"].value_counts()[:n].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j2fzwMuV0H43",
   "metadata": {
    "id": "j2fzwMuV0H43"
   },
   "outputs": [],
   "source": [
    "#top ten coutries - again not sure if we ened this\n",
    "#south africa is however third\n",
    "to_use[\"country\"].value_counts()[:n].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ce978-6d26-410d-b467-06d73300cf0d",
   "metadata": {},
   "source": [
    "# NEW CODES PLEASE READ THE NEW REASONING BEHIND THIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JmVtqNFt0H7N",
   "metadata": {
    "id": "JmVtqNFt0H7N"
   },
   "outputs": [],
   "source": [
    "#to get all the values corresponding to provoked\n",
    "#this is so far okay - we are going for provoked locations\n",
    "\n",
    "\n",
    "location_counts = to_use[\"location\"][to_use[\"type\"] == \"Provoked\"].value_counts()\n",
    "location_frequencies = to_use[\"location\"][to_use[\"type\"] == \"Provoked\"].value_counts().to_dict() #returns a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25b952-12cd-4d78-af33-7bcae9e69380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the 5 top locations are: \n",
    "#New Smyrna Beach, Volusia County': 6,\n",
    "#'Marineland, Sydney': 4,\n",
    " #'Florida Keys, Monroe County': 4,\n",
    "# 'Santa Monica, Los Angeles County': 3,\n",
    " #'Darwin': 3,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nl_7jdB90H90",
   "metadata": {
    "id": "nl_7jdB90H90"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_use' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m country_counts \u001b[38;5;241m=\u001b[39m to_use[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m][to_use[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvoked\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      2\u001b[0m country_frequences \u001b[38;5;241m=\u001b[39m to_use[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m][to_use[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvoked\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_use' is not defined"
     ]
    }
   ],
   "source": [
    "#this country count is useful only if we have country preferences \n",
    "country_counts = to_use[\"country\"][to_use[\"type\"] == \"Provoked\"].value_counts()\n",
    "country_frequences = to_use[\"country\"][to_use[\"type\"] == \"Provoked\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5991a4-04c9-4a86-bd55-682412d3dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 5 countries:\n",
    "#USA': 233,\n",
    "# 'AUSTRALIA': 144,\n",
    "# 'SOUTH AFRICA': 57,\n",
    " #'NEW ZEALAND': 21,\n",
    " #'BAHAMAS': 18,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebe624-33c9-42ed-a499-8b123d631e8a",
   "metadata": {},
   "source": [
    "# we were doing this earlier - but it is wrong - because it is species to type but not to location\n",
    "species_counts =to_use[\"species\"][to_use[\"type\"] == \"Provoked\"].value_counts()\n",
    "species_frequencies = to_use[\"species\"][to_use[\"type\"] == \"Provoked\"].value_counts().to_dict()\n",
    "\n",
    "# once we have decided on the location, which is, let's say, 'new smyrna beach, volusia county' we should see the top shark species there?\n",
    "# does this make sense? because provoked to species will give the most frequently occurring provoked attacks by type of sharks worldwide \n",
    "# we want location specific species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0e247-73f4-484b-96a5-1224e1481def",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_loc_freq = to_use[\"species\"][to_use[\"location\"] == \"New Smyrna Beach, Volusia County\"].value_counts().to_dict()\n",
    "species_loc_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec72d1e-eb8b-4527-94f4-7139973b60db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above gives us: {'spinner shark': 15, 'blacktip shark': 9, 'bull shark': 2, 'lemon shark': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RJ4aBuAfhUNV",
   "metadata": {
    "id": "RJ4aBuAfhUNV"
   },
   "source": [
    "WHAT TO DO WTIH THE NULL VALUES ?  HOW ARE WE FILLING IT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1NJYmvN30IDj",
   "metadata": {
    "id": "1NJYmvN30IDj"
   },
   "outputs": [],
   "source": [
    "#so now i will do a research on each "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wAE2ZUMAhQlA",
   "metadata": {
    "id": "wAE2ZUMAhQlA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4QjCJHOH0IFG",
   "metadata": {
    "id": "4QjCJHOH0IFG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
