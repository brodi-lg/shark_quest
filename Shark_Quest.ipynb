{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9812ab-aeb9-43c8-bcc7-abf97428425c",
   "metadata": {
    "id": "2e9812ab-aeb9-43c8-bcc7-abf97428425c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8hd77s_FlJZd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "8hd77s_FlJZd",
    "outputId": "0bd343ca-043a-4681-a23d-7d1dbd644d30"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"https://www.sharkattackfile.net/spreadsheets/GSAF5.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e728df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914248a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run Shark_Quest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef1f8a-d455-449e-976d-a60d0d1038cc",
   "metadata": {
    "id": "7eef1f8a-d455-449e-976d-a60d0d1038cc"
   },
   "outputs": [],
   "source": [
    "to_use.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lt3nSI4ylQhB",
   "metadata": {
    "id": "Lt3nSI4ylQhB"
   },
   "outputs": [],
   "source": [
    "data_1 = df.copy() #making first copy just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7db21-60b6-4b93-8495-4a040daa5159",
   "metadata": {
    "id": "d7d7db21-60b6-4b93-8495-4a040daa5159"
   },
   "source": [
    "# making a new data set with columns that we want to work with instead of dropping columns\n",
    "\n",
    "Here's how and logic: To select multiple columns, use a list of column names within the selection brackets\n",
    "    The inner square brackets define a Python list with column names,\n",
    "    whereas the outer brackets are used to select the data from a pandas DataFrame.\n",
    "    The returned data type is a pandas DataFrame. This method does not affect the rows. so we retain original rows\n",
    "\n",
    "# justification for keeping columns\n",
    "\n",
    "    1)data: there might be a particular season for attacks -we want to avoid that\n",
    "    2)year: we may look at this long term or select a period of time later - say 10 years\n",
    "    3)type: as discussed - unprovoked attacks might signal how dangerous the shark type is\n",
    "    4)country and location: we want to circle the hotspots\n",
    "    5)injury: not sure but maybe fatal ones could be useful\n",
    "    6)species: to find which ones require conservation\n",
    "    # age and sex and all that - not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZV3MQ6LdlU1F",
   "metadata": {
    "id": "ZV3MQ6LdlU1F"
   },
   "outputs": [],
   "source": [
    "to_use = data_1[[\"Year\",\"Type\",\"Country\",\"Location\",\"Injury\",\"Species \"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3PKKfHJilX99",
   "metadata": {
    "id": "3PKKfHJilX99"
   },
   "outputs": [],
   "source": [
    "#next step is data cleaning and standardisation - column names require cleaning - \"species \"has a white space\n",
    "to_use.columns = to_use.columns.str.replace(' ', '')\n",
    "to_use.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2998b5-67ec-4869-a926-239d3a04573e",
   "metadata": {
    "id": "1c2998b5-67ec-4869-a926-239d3a04573e"
   },
   "outputs": [],
   "source": [
    "to_use.columns = to_use.columns.str.lstrip().str.rstrip()\n",
    "to_use.columns = to_use.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96276bf4-9282-4c5e-aee4-670cdee9985e",
   "metadata": {
    "id": "96276bf4-9282-4c5e-aee4-670cdee9985e"
   },
   "outputs": [],
   "source": [
    "to_use.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b3efd-d758-4ef9-912d-cbc5b2e5e487",
   "metadata": {
    "id": "ee0b3efd-d758-4ef9-912d-cbc5b2e5e487"
   },
   "outputs": [],
   "source": [
    "to_use.dtypes #have to clear nans or have a strategy to clear nans before casting types i suppose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QFCA3DO5mju-",
   "metadata": {
    "id": "QFCA3DO5mju-"
   },
   "outputs": [],
   "source": [
    "to_use.duplicated().sum() #check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WA4SFGibnxUH",
   "metadata": {
    "id": "WA4SFGibnxUH"
   },
   "outputs": [],
   "source": [
    "#drop the duplicates\n",
    "to_use = to_use.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7gA2FRnaN2",
   "metadata": {
    "id": "cb7gA2FRnaN2"
   },
   "outputs": [],
   "source": [
    "#checking for empty spaces\n",
    "to_use.eq(\" \").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b5fa4-866d-4228-8f31-94cf21e3bab8",
   "metadata": {
    "id": "ea8b5fa4-866d-4228-8f31-94cf21e3bab8"
   },
   "source": [
    "# tasks to do:\n",
    "    - cleaning data set based on nans and what remains\n",
    "    - duplicates\n",
    "    - standardisation of column values\n",
    "    - then value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ddc5f",
   "metadata": {},
   "source": [
    "# cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QjZxuIj108gB",
   "metadata": {
    "id": "QjZxuIj108gB"
   },
   "outputs": [],
   "source": [
    "# year column\n",
    "\n",
    "to_use['year'] = to_use['year'].astype(str).str.replace(\".0\", \"\")\n",
    "to_use['year'] = to_use['year'].replace('nan', '0')\n",
    "to_use['year'] = to_use['year'].astype(int)\n",
    "to_use = to_use[to_use[\"year\"] >= 2000] #we sorted the years starting in 2000 till the actual year because that is what we want to analyze\n",
    "to_use = to_use.sort_values(by=\"year\", ascending=True)\n",
    "to_use = to_use[to_use[\"year\"] < 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Cx07HOj4kqd",
   "metadata": {
    "id": "5Cx07HOj4kqd"
   },
   "outputs": [],
   "source": [
    "#column type\n",
    "unwanted= [\"Invalid\", \"Watercraft\", \"Questionable\", \"Sea Disaster\", \"Under investigation\", \"Unverified\",\"Unconfirmed\", \"Boat\", \"?\"]\n",
    "to_use= to_use[to_use[\"type\"].apply(lambda x: x not in unwanted)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hlfc2bKA5ksE",
   "metadata": {
    "id": "hlfc2bKA5ksE"
   },
   "outputs": [],
   "source": [
    "to_use[\"type\"] = to_use[\"type\"].replace(\" Provoked\", \"Provoked\")\n",
    "to_use[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fh2H47UsI8PI",
   "metadata": {
    "id": "Fh2H47UsI8PI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_use = to_use.dropna(subset=[\"type\"])\n",
    "to_use.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "doZ68Mitg-Vy",
   "metadata": {
    "id": "doZ68Mitg-Vy"
   },
   "outputs": [],
   "source": [
    "#checking for duplicates\n",
    "to_use.duplicated().sum()\n",
    "to_use.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKsfyobxffHL",
   "metadata": {
    "id": "PKsfyobxffHL"
   },
   "outputs": [],
   "source": [
    "#finding nan values in year, location, country\n",
    "to_use[\"location\"].isna().sum()\n",
    "to_use[\"country\"].isna().sum()\n",
    "to_use[\"year\"].isna().sum()   #i checked and there were none in year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yc9o9v_v0Hy5",
   "metadata": {
    "id": "yc9o9v_v0Hy5"
   },
   "outputs": [],
   "source": [
    "#dropping nan values in country and location\n",
    "to_use.dropna(subset = ['country', 'location'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0d24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories of injury\n",
    "\n",
    "injuries_1 = [\"no injury\", \"rammed\", \"knocked\"]\n",
    "injuries_2 = [\"lacer\"]\n",
    "injuries_3 = [\"minor\", \"bitten\", \"injured\", \"puncture\", \"superficial\", \"cut\", \"pinched\", \"bruised\", \"gash\",\n",
    "             \"mark\", \"struck\", \"torn\"]\n",
    "injuries_4 = [\"major\", \"sever\", \"significant\", \"broken\", \"injuries\", \"injury\", \"multiple\", \"serious\",\n",
    "              \"gashed\", \"avulsed\", \"large\", \"lost\", \"amputated\"]\n",
    "injuries_5 = [\"fatal\", \"death\"]\n",
    "boat = [\"boat\", \"hull\", \"dinghy\", \"kayak\"]\n",
    "scavenging = [\"scavenging\"]\n",
    "\n",
    "all_injuries = injuries_1 + injuries_2 + injuries_3 + injuries_4 + injuries_5 + boat + scavenging\n",
    "\n",
    "def injury_rating(j):\n",
    "\n",
    "    \"\"\"categorising entries in the injury column\"\"\"\n",
    "\n",
    "    j = j.lower()\n",
    "    for i in injuries_1:\n",
    "        if i in j:\n",
    "            return \"no injury\"\n",
    "    for i in injuries_2:\n",
    "        if i in j:\n",
    "            return \"lacerations\"\n",
    "    for i in injuries_3:\n",
    "        if i in j:\n",
    "            return \"minor injuries\"\n",
    "    for i in injuries_4:\n",
    "        if i in j:\n",
    "            return \"major injuries\"\n",
    "    for i in injuries_5:\n",
    "        if i in j:\n",
    "            return \"fatal\"\n",
    "    for i in scavenging:\n",
    "        if i in j:\n",
    "            return \"probably scavenging\"\n",
    "    for i in boat:\n",
    "        if i in j:\n",
    "            return \"material damage\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af917dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_use[\"injury\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorising injuries\n",
    "to_use.dropna(subset=\"injury\", inplace=True)\n",
    "to_use[\"injury\"] = to_use[\"injury\"].apply(injury_rating)\n",
    "to_use.dropna(subset=\"injury\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569dd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorising shark species\n",
    "\n",
    "sharks = [\"white shark\", \"tiger shark\", \"bull shark\", \"shortfin mako shark\",\n",
    "         \"lemon shark\", \"oceanic whitetip shark\", \"blue shark\", \"galapagos shark\", \"caribbean reef shark\",\n",
    "         \"dusky shark\", \"blacktip shark\", \"silky shark\", \"gray reef shark\", \"great hammerhead shark\",\n",
    "         \"blacktip reef shark\", \"sevengill shark\", \"sixgill shark\", \"nurse shark\",\n",
    "         \"sand tiger\", \"spotted wobbegong\", \"basking shark\", \"spinner shark\", \"bronze whaler\", \"blue pointer\"]\n",
    "\n",
    "def shark_species(value, sharks):\n",
    "    for shark in sharks:\n",
    "        if shark in value.lower():\n",
    "            return shark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68d0908",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_use.dropna(subset=\"species\", inplace=True)\n",
    "to_use[\"species\"] = to_use[\"species\"].apply(shark_species, args=(sharks,))\n",
    "to_use[\"species\"] = to_use[\"species\"].replace(\"blue pointer\", \"shortfin mako shark\")\n",
    "to_use.dropna(subset=\"species\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ecf68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4a4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OJEnZjao0H2B",
   "metadata": {
    "id": "OJEnZjao0H2B"
   },
   "outputs": [],
   "source": [
    "#top ten locations - not sure if we need this\n",
    "n=10\n",
    "to_use[\"location\"].value_counts()[:n].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j2fzwMuV0H43",
   "metadata": {
    "id": "j2fzwMuV0H43"
   },
   "outputs": [],
   "source": [
    "#top ten coutries - again not sure if we ened this\n",
    "#south africa is however third\n",
    "to_use[\"country\"].value_counts()[:n].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e754f3a-7a80-4a95-ba94-f831c9958657",
   "metadata": {},
   "source": [
    "# codes for cleaning locations  - odi \n",
    "\n",
    "- i took the longest to decide what to do with the long county names.\n",
    "- option 1:  to group different places within the same county under the same county\n",
    "- option 2: to leave the county names are often preceded by very specific areas in the county (counties exist mainly in the US)\n",
    "  \n",
    "      does this seem correct to you all?\n",
    "- option 3: when you look at the dictionary returned against location and type (location_frequencies = to_use[\"location\"][to_use[\"type\"] == \"Provoked\"].value_counts().to_dict() # but this one returns a dictionary ) it gives different areas under the same county and their value count - now do you think if we group all areas under their common county names the result will change? and do we n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20998850-f3cd-483a-8e48-62ed3c4ad4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cleaning location\n",
    "to_use.dropna(subset = ['location'],inplace = True)\n",
    "to_use[\"location\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f67ccf7-94df-4350-80ec-f08d7764d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing numbers and special characters\n",
    "to_use['location'] = to_use['location'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a5515-1086-4477-8e70-ec70c75fd04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing spaces\n",
    "to_use['location'] = to_use['location'].str.strip().str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12071b07-3058-4e3d-9e80-d57b39716a9c",
   "metadata": {},
   "source": [
    "# cleaning country  - odi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9190e47-d427-421a-889d-751c185ad73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning country\n",
    "to_use['country'] = to_use['country'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b492c15-9982-43d1-a9fb-d5ccfc211cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning white spaces \n",
    "to_use[\"country\"] = to_use['country'].str.strip()\n",
    "to_use.country.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ce978-6d26-410d-b467-06d73300cf0d",
   "metadata": {},
   "source": [
    "# NEW CODES PLEASE READ THE NEW REASONING BEHIND THIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JmVtqNFt0H7N",
   "metadata": {
    "id": "JmVtqNFt0H7N"
   },
   "outputs": [],
   "source": [
    "#to get all the values corresponding to provoked\n",
    "#this is so far okay - we are going for provoked locations\n",
    "\n",
    "\n",
    "location_counts = to_use[\"location\"][to_use[\"type\"] == \"Provoked\"].value_counts() #same thing as below\n",
    "location_frequencies = to_use[\"location\"][to_use[\"type\"] == \"Provoked\"].value_counts().to_dict() # but this one returns a dictionary \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nl_7jdB90H90",
   "metadata": {
    "id": "nl_7jdB90H90"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_use' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m country_counts \u001b[38;5;241m=\u001b[39m to_use[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m][to_use[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvoked\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      2\u001b[0m country_frequences \u001b[38;5;241m=\u001b[39m to_use[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m][to_use[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvoked\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_use' is not defined"
     ]
    }
   ],
   "source": [
    "#this country count is useful only if we have country preferences \n",
    "country_counts = to_use[\"country\"][to_use[\"type\"] == \"Provoked\"].value_counts()\n",
    "country_frequencies = to_use[\"country\"][to_use[\"type\"] == \"Provoked\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055767d-a78d-4d75-b800-2303cf16d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_counts = to_use[\"species\"][to_use[\"type\"] == \"Provoked\"].value_counts()\n",
    "species_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebe624-33c9-42ed-a499-8b123d631e8a",
   "metadata": {},
   "source": [
    "# we were doing this earlier - but it is wrong - because it is species to type but not to location\n",
    "species_counts =to_use[\"species\"][to_use[\"type\"] == \"Provoked\"].value_counts()\n",
    "species_frequencies = to_use[\"species\"][to_use[\"type\"] == \"Provoked\"].value_counts().to_dict()\n",
    "\n",
    "# we could choose one or could choose multiple - i've done the count for all - location_counts\n",
    "# does this make sense? because provoked to species will give the most frequently occurring provoked attacks by type of sharks worldwide \n",
    "# we want location specific species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1NJYmvN30IDj",
   "metadata": {
    "id": "1NJYmvN30IDj"
   },
   "outputs": [],
   "source": [
    "#so now i will do a research on each #check word doc\n",
    "#in key largo monroe county\n",
    "#check if this is the same for you\n",
    "species_loc_freq = to_use[\"species\"][to_use[\"location\"] == \"Key Largo Monroe County\"].value_counts().to_dict()\n",
    "species_loc_freq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac3b5ee-5d4e-4e74-a88c-0e3ea4fbb19f",
   "metadata": {
    "id": "wAE2ZUMAhQlA"
   },
   "outputs": [],
   "source": [
    "#in blue planet aquarium ellesmere port\"\n",
    "species_loc_freq = to_use[\"species\"][to_use[\"location\"] == \"Blue Planet Aquarium Ellesmere Port\"].value_counts().to_dict()\n",
    "species_loc_freq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4QjCJHOH0IFG",
   "metadata": {
    "id": "4QjCJHOH0IFG"
   },
   "outputs": [],
   "source": [
    "#in puerto escondido\n",
    "species_loc_freq = to_use[\"species\"][to_use[\"location\"] == \"Puerto Escondido\"].value_counts().to_dict()\n",
    "species_loc_freq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedf79ce-e30a-4c12-aead-f04eb4631ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lauderdale by the Sea Broward County (this is a hyphenated name anyway officially)\n",
    "species_loc_freq = to_use[\"species\"][to_use[\"location\"] == \"LauderdalebytheSea Broward County\"].value_counts().to_dict()\n",
    "species_loc_freq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35639279-6de9-4437-895b-74fc97443b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Croker Island\"\n",
    "species_loc_freq = to_use[\"species\"][to_use[\"location\"] == \"Near Croker Island\"].value_counts().to_dict()\n",
    "species_loc_freq "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
